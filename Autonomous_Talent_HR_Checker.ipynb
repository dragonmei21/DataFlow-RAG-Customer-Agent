{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Project 2: TalentFlow Autonomous HR Agent\n",
    "## Part 1: Setup + Resume Intelligence Agent\n",
    "\n",
    "**Goal**: Build a complete autonomous HR recruitment system that processes resumes, makes hiring decisions, and generates communications without human intervention\n",
    "\n",
    "**Business Problem**: HR teams spend 40+ hours per hire on manual tasks - screening resumes, scheduling interviews, writing emails. This costs $3,000+ per hire in time.\n",
    "\n",
    "**Our Solution**: Autonomous AI agents that independently process candidates, make decisions, and take actions - reducing hiring time from 40 hours to 4 hours (90% automation).\n",
    "\n",
    "**Expected ROI**: $2,800+ savings per hire, 30% faster time-to-hire, 25% better candidate matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Setup & Dependencies\n",
    "\n",
    "**What we'll use:**\n",
    "- **LangChain**: Agent orchestration and autonomous workflows\n",
    "- **Ollama**: Free local LLM (with OpenAI option)\n",
    "- **Python**: File processing and automation\n",
    "- **Real Data**: 10 candidate resumes + job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n",
      "üìÅ Current directory: /Users/ellamagdic/Desktop/AIAgentsBootcamp/Section_5_Autonomous_Workflows\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Optional: Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"üìÅ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß LLM Setup - Dual Strategy (Ollama + OpenAI)\n",
    "\n",
    "**Smart approach**: Use free Ollama by default, with OpenAI as premium option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜì Using Ollama (free local LLM)\n",
      "‚úÖ Ollama connected successfully!\n",
      "ü§ñ LLM ready: ollama\n"
     ]
    }
   ],
   "source": [
    "def setup_llm(use_openai=False):\n",
    "    \"\"\"Setup LLM with dual strategy: Ollama (free) or OpenAI (premium)\"\"\"\n",
    "    \n",
    "    if use_openai and os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"üîë Using OpenAI GPT-4 (premium option)\")\n",
    "        return ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.1,\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        ), \"openai\"\n",
    "    else:\n",
    "        print(\"üÜì Using Ollama (free local LLM)\")\n",
    "        try:\n",
    "            llm = OllamaLLM(model=\"llama3.2\", base_url=\"http://localhost:11434\")\n",
    "            # Test connection\n",
    "            test_response = llm.invoke(\"Hello\")\n",
    "            print(\"‚úÖ Ollama connected successfully!\")\n",
    "            return llm, \"ollama\"\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Ollama connection failed: {e}\")\n",
    "            print(\"üí° Make sure Ollama is running: 'ollama serve' and 'ollama pull llama3.2'\")\n",
    "            return None, \"none\"\n",
    "\n",
    "# Setup LLM (change to True if you want to use OpenAI)\n",
    "llm, llm_type = setup_llm(use_openai=False)\n",
    "\n",
    "if llm:\n",
    "    print(f\"ü§ñ LLM ready: {llm_type}\")\n",
    "else:\n",
    "    print(\"‚ùå No LLM available - please check setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Data Loading & Validation\n",
    "\n",
    "**Load our complete dataset**: Job description + 10 candidate resumes + email templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading TalentFlow project data...\n",
      "========================================\n",
      "‚ö†Ô∏è Job description not found: /Users/ellamagdic/Desktop/AIAgentsBootcamp/Section_5_Autonomous_Workflows/data/Job Description - Software Engineer.markdown\n",
      "üìÑ Found 10 resume files\n",
      "   üìã John Smith: 127 words\n",
      "   üìã Jennifer Wilson: 132 words\n",
      "   üìã Robert Johnson: 144 words\n",
      "   üìã Emily Watson: 206 words\n",
      "   üìã Alex Thompson: 214 words\n",
      "   üìã Lisa Park: 187 words\n",
      "   üìã Mike Rodriguez: 140 words\n",
      "   üìã David Kim: 165 words\n",
      "   üìã Sarah Chen: 179 words\n",
      "   üìã Maria Garcia: 184 words\n",
      "\n",
      "üìä Data Summary:\n",
      "   üìù Job description: ‚ùå Missing\n",
      "   üìÑ Candidate resumes: 10\n",
      "   ‚úâÔ∏è Email templates: 0\n",
      "\n",
      "üéØ Ready to build autonomous HR agent!\n"
     ]
    }
   ],
   "source": [
    "def load_project_data():\n",
    "    \"\"\"Load all project data and validate structure\"\"\"\n",
    "    \n",
    "    data_dir = Path(\"/Users/ellamagdic/Desktop/AIAgentsBootcamp/Section_5_Autonomous_Workflows/data\")\n",
    "    \n",
    "    # Check if data directory exists\n",
    "    if not data_dir.exists():\n",
    "        print(f\"‚ùå Data directory not found: {data_dir.absolute()}\")\n",
    "        print(\"üí° Make sure you're running from Section_5_Autonomous_Workflows directory\")\n",
    "        return None\n",
    "    \n",
    "    project_data = {\n",
    "        \"job_description\": None,\n",
    "        \"resumes\": {},\n",
    "        \"templates\": {},\n",
    "        \"metadata\": {\n",
    "            \"loaded_at\": datetime.now().isoformat(),\n",
    "            \"total_candidates\": 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Load job description\n",
    "    job_desc_path = data_dir / \"Job Description - Software Engineer.markdown\"\n",
    "    if job_desc_path.exists():\n",
    "        with open(job_desc_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            project_data[\"job_description\"] = f.read()\n",
    "        print(f\"‚úÖ Job description loaded ({len(project_data['job_description'])} chars)\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Job description not found: {job_desc_path}\")\n",
    "    \n",
    "    # Load resumes\n",
    "    resumes_dir = data_dir / \"resumes\"\n",
    "    if resumes_dir.exists():\n",
    "        resume_files = list(resumes_dir.glob(\"*.markdown\"))\n",
    "        print(f\"üìÑ Found {len(resume_files)} resume files\")\n",
    "        \n",
    "        for resume_file in resume_files:\n",
    "            candidate_name = resume_file.stem.replace(\"Resume - \", \"\")\n",
    "            try:\n",
    "                with open(resume_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                    resume_content = f.read()\n",
    "                project_data[\"resumes\"][candidate_name] = {\n",
    "                    \"content\": resume_content,\n",
    "                    \"filename\": resume_file.name,\n",
    "                    \"word_count\": len(resume_content.split())\n",
    "                }\n",
    "                print(f\"   üìã {candidate_name}: {len(resume_content.split())} words\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error loading {resume_file.name}: {e}\")\n",
    "    \n",
    "    # Load email templates\n",
    "    templates_dir = data_dir / \"templates\"\n",
    "    if templates_dir.exists():\n",
    "        template_files = list(templates_dir.glob(\"*.md\"))\n",
    "        for template_file in template_files:\n",
    "            template_name = template_file.stem\n",
    "            try:\n",
    "                with open(template_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                    project_data[\"templates\"][template_name] = f.read()\n",
    "                print(f\"‚úâÔ∏è Template loaded: {template_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading template {template_file.name}: {e}\")\n",
    "    \n",
    "    project_data[\"metadata\"][\"total_candidates\"] = len(project_data[\"resumes\"])\n",
    "    \n",
    "    return project_data\n",
    "\n",
    "# Load all data\n",
    "print(\"üìÇ Loading TalentFlow project data...\")\n",
    "print(\"=\" * 40)\n",
    "data = load_project_data()\n",
    "\n",
    "if data:\n",
    "    print(\"\\nüìä Data Summary:\")\n",
    "    print(f\"   üìù Job description: {'‚úÖ Loaded' if data['job_description'] else '‚ùå Missing'}\")\n",
    "    print(f\"   üìÑ Candidate resumes: {len(data['resumes'])}\")\n",
    "    print(f\"   ‚úâÔ∏è Email templates: {len(data['templates'])}\")\n",
    "    print(\"\\nüéØ Ready to build autonomous HR agent!\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to load data - check file paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Resume Intelligence Agent üß†\n",
    "\n",
    "**Goal**: Build an AI agent that automatically analyzes resumes and extracts key information\n",
    "\n",
    "**What makes this autonomous**: The agent independently processes each resume, extracts structured data, and prepares it for decision-making without human intervention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Resume Analysis Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Resume Intelligence Agent initialized!\n",
      "‚úÖ Ready to process candidate resumes autonomously\n"
     ]
    }
   ],
   "source": [
    "class ResumeIntelligenceAgent:\n",
    "    \"\"\"Autonomous agent for resume analysis and information extraction\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.analysis_count = 0\n",
    "        self.processing_times = []\n",
    "        \n",
    "        # Define extraction prompt template\n",
    "        self.extraction_prompt = PromptTemplate(\n",
    "            input_variables=[\"resume_content\"],\n",
    "            template=\"\"\"Analyze this resume and extract key information in JSON format.\n",
    "\n",
    "Resume Content:\n",
    "{resume_content}\n",
    "\n",
    "Extract the following information and return ONLY valid JSON:\n",
    "{{\n",
    "  \"name\": \"candidate full name\",\n",
    "  \"experience_years\": \"number of years of relevant experience\",\n",
    "  \"current_title\": \"most recent job title\",\n",
    "  \"key_skills\": [\"list\", \"of\", \"main\", \"technical\", \"skills\"],\n",
    "  \"education\": \"highest degree and school\",\n",
    "  \"summary\": \"2-3 sentence professional summary\"\n",
    "}}\n",
    "\n",
    "IMPORTANT: Return only the JSON object, no other text.\"\"\"\n",
    "        )\n",
    "    \n",
    "    def extract_resume_info(self, resume_content: str, candidate_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract structured information from resume content\"\"\"\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Format prompt\n",
    "            formatted_prompt = self.extraction_prompt.format(resume_content=resume_content)\n",
    "            \n",
    "            # Get LLM response\n",
    "            if hasattr(self.llm, 'invoke'):\n",
    "                response = self.llm.invoke(formatted_prompt)\n",
    "            else:\n",
    "                response = self.llm(formatted_prompt)\n",
    "            \n",
    "            # Try to parse JSON response\n",
    "            try:\n",
    "                # Clean response (remove markdown formatting if present)\n",
    "                clean_response = response.strip()\n",
    "                if clean_response.startswith('```json'):\n",
    "                    clean_response = clean_response[7:]\n",
    "                if clean_response.endswith('```'):\n",
    "                    clean_response = clean_response[:-3]\n",
    "                \n",
    "                extracted_info = json.loads(clean_response)\n",
    "                \n",
    "                # Add metadata\n",
    "                extracted_info[\"candidate_id\"] = candidate_name\n",
    "                extracted_info[\"processed_at\"] = datetime.now().isoformat()\n",
    "                extracted_info[\"extraction_success\"] = True\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"‚ö†Ô∏è JSON parsing failed for {candidate_name}, using fallback extraction\")\n",
    "                extracted_info = self._fallback_extraction(resume_content, candidate_name)\n",
    "            \n",
    "            # Track performance\n",
    "            processing_time = time.time() - start_time\n",
    "            self.processing_times.append(processing_time)\n",
    "            self.analysis_count += 1\n",
    "            \n",
    "            extracted_info[\"processing_time\"] = processing_time\n",
    "            \n",
    "            return extracted_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {candidate_name}: {e}\")\n",
    "            return self._fallback_extraction(resume_content, candidate_name)\n",
    "    \n",
    "    def _fallback_extraction(self, resume_content: str, candidate_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"Fallback extraction using simple text analysis\"\"\"\n",
    "        \n",
    "        lines = resume_content.split('\\n')\n",
    "        \n",
    "        # Simple extraction logic\n",
    "        name = candidate_name.replace('_', ' ').title()\n",
    "        \n",
    "        # Look for years of experience\n",
    "        experience_years = \"Unknown\"\n",
    "        for line in lines:\n",
    "            if \"year\" in line.lower() and \"experience\" in line.lower():\n",
    "                experience_years = line.strip()\n",
    "                break\n",
    "        \n",
    "        # Extract skills (look for technical skills section)\n",
    "        skills = []\n",
    "        in_skills_section = False\n",
    "        for line in lines:\n",
    "            if \"skill\" in line.lower() or \"technolog\" in line.lower():\n",
    "                in_skills_section = True\n",
    "            elif in_skills_section and line.strip() and not line.startswith('#'):\n",
    "                # Extract skills from line\n",
    "                if ':' in line:\n",
    "                    skills.extend([s.strip() for s in line.split(':')[1].split(',')])\n",
    "        \n",
    "        return {\n",
    "            \"name\": name,\n",
    "            \"experience_years\": experience_years,\n",
    "            \"current_title\": \"Not extracted\",\n",
    "            \"key_skills\": skills[:5],  # Limit to 5 skills\n",
    "            \"education\": \"Not extracted\",\n",
    "            \"summary\": f\"Resume analysis for {name}\",\n",
    "            \"candidate_id\": candidate_name,\n",
    "            \"processed_at\": datetime.now().isoformat(),\n",
    "            \"extraction_success\": False,\n",
    "            \"processing_time\": 0.1\n",
    "        }\n",
    "    \n",
    "    def get_agent_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get performance statistics for the agent\"\"\"\n",
    "        \n",
    "        if not self.processing_times:\n",
    "            return {\"analyses_completed\": 0, \"avg_processing_time\": 0}\n",
    "        \n",
    "        return {\n",
    "            \"analyses_completed\": self.analysis_count,\n",
    "            \"avg_processing_time\": sum(self.processing_times) / len(self.processing_times),\n",
    "            \"fastest_analysis\": min(self.processing_times),\n",
    "            \"slowest_analysis\": max(self.processing_times),\n",
    "            \"total_processing_time\": sum(self.processing_times)\n",
    "        }\n",
    "\n",
    "# Create the resume intelligence agent\n",
    "if llm:\n",
    "    resume_agent = ResumeIntelligenceAgent(llm)\n",
    "    print(\"üß† Resume Intelligence Agent initialized!\")\n",
    "    print(\"‚úÖ Ready to process candidate resumes autonomously\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot create agent - LLM not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Process All Candidates Autonomously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting autonomous resume processing...\n",
      "==================================================\n",
      "\n",
      "üìã Processing: John Smith\n",
      "   üìÑ Resume length: 127 words\n",
      "   üë§ Name: John Smith\n",
      "   üíº Experience: 6\n",
      "   üéØ Title: Junior Web Developer\n",
      "   üîß Key Skills: HTML, CSS, JavaScript\n",
      "   ‚è±Ô∏è Processed in: 6.02s\n",
      "   ‚úÖ Extraction: Success\n",
      "\n",
      "üìã Processing: Jennifer Wilson\n",
      "   üìÑ Resume length: 132 words\n",
      "‚ö†Ô∏è JSON parsing failed for Jennifer Wilson, using fallback extraction\n",
      "   üë§ Name: Jennifer Wilson\n",
      "   üíº Experience: **Data Analyst | 2 years experience**\n",
      "   üéØ Title: Not extracted\n",
      "   üîß Key Skills: ** Python (pandas, numpy), SQL\n",
      "   ‚è±Ô∏è Processed in: 10.39s\n",
      "   ‚ö†Ô∏è Extraction: Fallback\n",
      "\n",
      "üìã Processing: Robert Johnson\n",
      "   üìÑ Resume length: 144 words\n",
      "   üë§ Name: Robert Johnson\n",
      "   üíº Experience: 8\n",
      "   üéØ Title: Marketing Manager | Consumer Goods Corp\n",
      "   üîß Key Skills: Digital Marketing (Google Ads, Facebook Ads), Content Creation and Copywriting, Data Analysis (Excel, Google Analytics)\n",
      "   ‚è±Ô∏è Processed in: 7.79s\n",
      "   ‚úÖ Extraction: Success\n",
      "\n",
      "üìã Processing: Emily Watson\n",
      "   üìÑ Resume length: 206 words\n",
      "   üë§ Name: Emily Watson\n",
      "   üíº Experience: 5\n",
      "   üéØ Title: Senior Full Stack Engineer | CloudTech Corp \n",
      "   üîß Key Skills: Python, TypeScript, JavaScript\n",
      "   ‚è±Ô∏è Processed in: 8.04s\n",
      "   ‚úÖ Extraction: Success\n",
      "\n",
      "üìã Processing: Alex Thompson\n",
      "   üìÑ Resume length: 214 words\n",
      "   üë§ Name: Alex Thompson\n",
      "   üíº Experience: 4\n",
      "   üéØ Title: Senior Software Engineer\n",
      "   üîß Key Skills: TypeScript, React, Node.js\n",
      "   ‚è±Ô∏è Processed in: 7.13s\n",
      "   ‚úÖ Extraction: Success\n",
      "\n",
      "üìã Processing: Lisa Park\n",
      "   üìÑ Resume length: 187 words\n",
      "   üë§ Name: Lisa Park\n",
      "   üíº Experience: 3\n",
      "   üéØ Title: Software Engineer\n",
      "   üîß Key Skills: Python, JavaScript, TypeScript\n",
      "   ‚è±Ô∏è Processed in: 7.62s\n",
      "   ‚úÖ Extraction: Success\n",
      "\n",
      "üìã Processing: Mike Rodriguez\n",
      "   üìÑ Resume length: 140 words\n",
      "   üë§ Name: Mike Rodriguez\n",
      "   üíº Experience: 3\n",
      "   üéØ Title: Full Stack Developer | WebSolutions LLC\n",
      "   üîß Key Skills: Python, JavaScript, PHP\n",
      "   ‚è±Ô∏è Processed in: 6.84s\n",
      "   ‚úÖ Extraction: Success\n",
      "\n",
      "üìã Processing: David Kim\n",
      "   üìÑ Resume length: 165 words\n",
      "   üë§ Name: David Kim\n",
      "   üíº Experience: 2\n",
      "   üéØ Title: Backend Developer | API Solutions Inc\n",
      "   üîß Key Skills: Python, SQL, JavaScript\n",
      "   ‚è±Ô∏è Processed in: 8.68s\n",
      "   ‚úÖ Extraction: Success\n",
      "\n",
      "üìã Processing: Sarah Chen\n",
      "   üìÑ Resume length: 179 words\n",
      "   üë§ Name: Sarah Chen\n",
      "   üíº Experience: 4\n",
      "   üéØ Title: Senior Software Engineer\n",
      "   üîß Key Skills: Python, JavaScript, TypeScript\n",
      "   ‚è±Ô∏è Processed in: 7.56s\n",
      "   ‚úÖ Extraction: Success\n",
      "\n",
      "üìã Processing: Maria Garcia\n",
      "   üìÑ Resume length: 184 words\n",
      "   üë§ Name: Maria Garcia\n",
      "   üíº Experience: 2.5\n",
      "   üéØ Title: Full Stack Developer | WebApp Solutions\n",
      "   üîß Key Skills: Python, JavaScript, React\n",
      "   ‚è±Ô∏è Processed in: 5.44s\n",
      "   ‚úÖ Extraction: Success\n",
      "\n",
      "üéâ AUTONOMOUS PROCESSING COMPLETE!\n",
      "==================================================\n",
      "üìä Agent Performance:\n",
      "   üìÑ Resumes processed: 20\n",
      "   ‚è±Ô∏è Average time per resume: 7.39s\n",
      "   üèÉ Total processing time: 147.77s\n",
      "\n",
      "üí∞ Time Savings Calculation:\n",
      "   ‚è∞ Manual processing: 60.0 minutes\n",
      "   ü§ñ AI processing: 2.5 minutes\n",
      "   üíé Time saved: 57.5 minutes (95.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "def process_all_resumes(agent, resume_data):\n",
    "    \"\"\"Autonomous processing of all candidate resumes\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting autonomous resume processing...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    processed_candidates = {}\n",
    "    \n",
    "    for candidate_name, resume_info in resume_data.items():\n",
    "        print(f\"\\nüìã Processing: {candidate_name}\")\n",
    "        print(f\"   üìÑ Resume length: {resume_info['word_count']} words\")\n",
    "        \n",
    "        # Extract information using the agent\n",
    "        extracted_info = agent.extract_resume_info(\n",
    "            resume_info['content'], \n",
    "            candidate_name\n",
    "        )\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"   üë§ Name: {extracted_info.get('name', 'Not found')}\")\n",
    "        print(f\"   üíº Experience: {extracted_info.get('experience_years', 'Not found')}\")\n",
    "        print(f\"   üéØ Title: {extracted_info.get('current_title', 'Not found')}\")\n",
    "        print(f\"   üîß Key Skills: {', '.join(extracted_info.get('key_skills', [])[:3])}\")\n",
    "        print(f\"   ‚è±Ô∏è Processed in: {extracted_info.get('processing_time', 0):.2f}s\")\n",
    "        \n",
    "        success_icon = \"‚úÖ\" if extracted_info.get('extraction_success', False) else \"‚ö†Ô∏è\"\n",
    "        print(f\"   {success_icon} Extraction: {'Success' if extracted_info.get('extraction_success', False) else 'Fallback'}\")\n",
    "        \n",
    "        processed_candidates[candidate_name] = extracted_info\n",
    "    \n",
    "    return processed_candidates\n",
    "\n",
    "# Process all resumes autonomously\n",
    "if llm and data and data['resumes']:\n",
    "    processed_resumes = process_all_resumes(resume_agent, data['resumes'])\n",
    "    \n",
    "    print(\"\\nüéâ AUTONOMOUS PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Show agent performance\n",
    "    stats = resume_agent.get_agent_stats()\n",
    "    print(f\"üìä Agent Performance:\")\n",
    "    print(f\"   üìÑ Resumes processed: {stats['analyses_completed']}\")\n",
    "    print(f\"   ‚è±Ô∏è Average time per resume: {stats.get('avg_processing_time', 0):.2f}s\")\n",
    "    print(f\"   üèÉ Total processing time: {stats.get('total_processing_time', 0):.2f}s\")\n",
    "    \n",
    "    # Calculate time savings\n",
    "    manual_time_per_resume = 6 * 60  # 6 minutes per resume manually\n",
    "    total_manual_time = manual_time_per_resume * len(processed_resumes)\n",
    "    total_ai_time = stats.get('total_processing_time', 0)\n",
    "    time_saved = total_manual_time - total_ai_time\n",
    "    \n",
    "    print(f\"\\nüí∞ Time Savings Calculation:\")\n",
    "    print(f\"   ‚è∞ Manual processing: {total_manual_time/60:.1f} minutes\")\n",
    "    print(f\"   ü§ñ AI processing: {total_ai_time/60:.1f} minutes\")\n",
    "    print(f\"   üíé Time saved: {time_saved/60:.1f} minutes ({(time_saved/total_manual_time)*100:.1f}% reduction)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot process resumes - missing LLM or data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Detailed Candidate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä DETAILED CANDIDATE ANALYSIS\n",
      "==================================================\n",
      "\n",
      "üîß TOP SKILLS ACROSS ALL CANDIDATES:\n",
      "   ‚Ä¢ Javascript: 7 candidates\n",
      "   ‚Ä¢ Python: 7 candidates\n",
      "   ‚Ä¢ React: 6 candidates\n",
      "   ‚Ä¢ Sql: 5 candidates\n",
      "   ‚Ä¢ Django: 5 candidates\n",
      "   ‚Ä¢ Node.Js: 5 candidates\n",
      "   ‚Ä¢ Postgresql: 5 candidates\n",
      "   ‚Ä¢ Aws: 5 candidates\n",
      "   ‚Ä¢ Typescript: 4 candidates\n",
      "   ‚Ä¢ Fastapi: 4 candidates\n",
      "\n",
      "üíº EXPERIENCE LEVEL DISTRIBUTION:\n",
      "   ‚Ä¢ Entry-level: 2 candidates (20.0%)\n",
      "   ‚Ä¢ Mid-level (2-3 years): 4 candidates (40.0%)\n",
      "   ‚Ä¢ Senior (4+ years): 4 candidates (40.0%)\n",
      "\n",
      "üìà PROCESSING QUALITY METRICS:\n",
      "   ‚úÖ Successful AI extractions: 9/10 (90.0%)\n",
      "   ‚ö†Ô∏è Fallback extractions: 1\n",
      "\n",
      "üåü CANDIDATE PROFILES PREVIEW:\n",
      "\n",
      "   1. John Smith\n",
      "      üíº Junior Web Developer\n",
      "      üéì B.A. Communications, Local College\n",
      "      üîß Skills: HTML, CSS, JavaScript, Python\n",
      "\n",
      "   2. Jennifer Wilson\n",
      "      üíº Not extracted\n",
      "      üéì Not extracted\n",
      "      üîß Skills: ** Python (pandas, numpy), SQL, R\n",
      "\n",
      "   3. Robert Johnson\n",
      "      üíº Marketing Manager | Consumer Goods Corp\n",
      "      üéì MBA Marketing | Business School, B.A. Business Administration | State University\n",
      "      üîß Skills: Digital Marketing (Google Ads, Facebook Ads), Content Creation and Copywriting, Data Analysis (Excel, Google Analytics), Project Management\n"
     ]
    }
   ],
   "source": [
    "def analyze_candidate_profiles(processed_resumes):\n",
    "    \"\"\"Analyze and display detailed candidate profiles\"\"\"\n",
    "    \n",
    "    if not processed_resumes:\n",
    "        print(\"‚ùå No processed resumes available for analysis\")\n",
    "        return\n",
    "    \n",
    "    print(\"üìä DETAILED CANDIDATE ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Skills analysis\n",
    "    all_skills = []\n",
    "    for candidate_info in processed_resumes.values():\n",
    "        skills = candidate_info.get('key_skills', [])\n",
    "        all_skills.extend([skill.lower().strip() for skill in skills])\n",
    "    \n",
    "    # Count skill frequency\n",
    "    skill_counts = {}\n",
    "    for skill in all_skills:\n",
    "        if skill and len(skill) > 2:  # Filter out empty or very short skills\n",
    "            skill_counts[skill] = skill_counts.get(skill, 0) + 1\n",
    "    \n",
    "    # Top skills\n",
    "    top_skills = sorted(skill_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    print(f\"\\nüîß TOP SKILLS ACROSS ALL CANDIDATES:\")\n",
    "    for skill, count in top_skills:\n",
    "        print(f\"   ‚Ä¢ {skill.title()}: {count} candidates\")\n",
    "    \n",
    "    # Experience distribution\n",
    "    experience_levels = {}\n",
    "    for candidate_info in processed_resumes.values():\n",
    "        exp = str(candidate_info.get('experience_years', 'Unknown')).lower()\n",
    "        if 'unknown' in exp or 'not' in exp:\n",
    "            level = 'Unknown'\n",
    "        elif any(x in exp for x in ['5+', '4+', '5', '4']):\n",
    "            level = 'Senior (4+ years)'\n",
    "        elif any(x in exp for x in ['3', '2']):\n",
    "            level = 'Mid-level (2-3 years)'\n",
    "        elif '1' in exp:\n",
    "            level = 'Junior (1 year)'\n",
    "        else:\n",
    "            level = 'Entry-level'\n",
    "        \n",
    "        experience_levels[level] = experience_levels.get(level, 0) + 1\n",
    "    \n",
    "    print(f\"\\nüíº EXPERIENCE LEVEL DISTRIBUTION:\")\n",
    "    for level, count in experience_levels.items():\n",
    "        percentage = (count / len(processed_resumes)) * 100\n",
    "        print(f\"   ‚Ä¢ {level}: {count} candidates ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Processing success rate\n",
    "    successful_extractions = sum(1 for info in processed_resumes.values() \n",
    "                                if info.get('extraction_success', False))\n",
    "    success_rate = (successful_extractions / len(processed_resumes)) * 100\n",
    "    \n",
    "    print(f\"\\nüìà PROCESSING QUALITY METRICS:\")\n",
    "    print(f\"   ‚úÖ Successful AI extractions: {successful_extractions}/{len(processed_resumes)} ({success_rate:.1f}%)\")\n",
    "    print(f\"   ‚ö†Ô∏è Fallback extractions: {len(processed_resumes) - successful_extractions}\")\n",
    "    \n",
    "    # Top candidates preview\n",
    "    print(f\"\\nüåü CANDIDATE PROFILES PREVIEW:\")\n",
    "    for i, (candidate_id, info) in enumerate(list(processed_resumes.items())[:3], 1):\n",
    "        print(f\"\\n   {i}. {info.get('name', candidate_id)}\")\n",
    "        print(f\"      üíº {info.get('current_title', 'Title not extracted')}\")\n",
    "        print(f\"      üéì {info.get('education', 'Education not extracted')}\")\n",
    "        print(f\"      üîß Skills: {', '.join(info.get('key_skills', [])[:4])}\")\n",
    "    \n",
    "    return {\n",
    "        \"top_skills\": top_skills,\n",
    "        \"experience_distribution\": experience_levels,\n",
    "        \"success_rate\": success_rate,\n",
    "        \"total_candidates\": len(processed_resumes)\n",
    "    }\n",
    "\n",
    "# Analyze candidate profiles\n",
    "if 'processed_resumes' in locals() and processed_resumes:\n",
    "    analysis_results = analyze_candidate_profiles(processed_resumes)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No processed resumes available - run the processing cell first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Export Processed Data for Next Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No processed resumes to export\n",
      "üí° Please run the resume processing cells above first\n"
     ]
    }
   ],
   "source": [
    "# Prepare data export for subsequent parts\n",
    "def export_part1_results():\n",
    "    \"\"\"Export results from Part 1 for use in subsequent parts\"\"\"\n",
    "    \n",
    "    export_data = {\n",
    "        \"processed_resumes\": processed_resumes if 'processed_resumes' in locals() else [],\n",
    "        \"resume_agent_stats\": resume_agent.get_agent_stats() if 'resume_agent' in locals() else {},\n",
    "        \"project_data\": data if 'data' in locals() else {},\n",
    "        \"llm_available\": llm is not None if 'llm' in locals() else False,\n",
    "        \"llm_type\": llm_type if 'llm_type' in locals() else \"none\"\n",
    "    }\n",
    "    \n",
    "    print(\"üì§ PART 1 RESULTS SUMMARY:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"‚úÖ Candidates processed: {len(export_data['processed_resumes'])}\")\n",
    "    print(f\"ü§ñ LLM available: {export_data['llm_available']} ({export_data['llm_type']})\")\n",
    "    print(f\"üìä Agent performance tracked: {bool(export_data['resume_agent_stats'])}\")\n",
    "    print(f\"üìÅ Project data loaded: {bool(export_data['project_data'])}\")\n",
    "    \n",
    "    if export_data['processed_resumes']:\n",
    "        print(f\"\\nüéØ Ready for Part 2: Decision Engine Agent\")\n",
    "        print(f\"   The processed resume data will be used for candidate scoring\")\n",
    "        print(f\"   Expected outcomes: Autonomous hiring decisions with 7-10 point scoring\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è No processed resumes available for Part 2\")\n",
    "        print(f\"   Please ensure Part 1 completed successfully before proceeding\")\n",
    "    \n",
    "    return export_data\n",
    "\n",
    "# Export results and save to file\n",
    "if 'processed_resumes' in locals() and processed_resumes:\n",
    "    try:\n",
    "        # Export summary\n",
    "        results_summary = export_part1_results()\n",
    "        \n",
    "        # Save processed resumes for Part 2\n",
    "        with open('processed_resumes.json', 'w') as f:\n",
    "            json.dump(processed_resumes, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nüíæ Data exported successfully:\")\n",
    "        print(f\"   ‚Ä¢ processed_resumes.json ({len(processed_resumes)} candidates)\")\n",
    "        print(f\"\\nüîÑ Ready to proceed to Part 2: Decision Engine Agent\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Export failed: {e}\")\n",
    "        print(f\"üîß Please check file permissions and try again\")\n",
    "else:\n",
    "    print(\"‚ùå No processed resumes to export\")\n",
    "    print(\"üí° Please run the resume processing cells above first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üéØ Part 1 Complete: Resume Intelligence Agent Ready!\n",
    "\n",
    "## What You've Built\n",
    "\n",
    "‚úÖ **Complete Setup Environment** - LLM configuration with Ollama/OpenAI dual strategy  \n",
    "‚úÖ **Data Loading System** - Automated loading of job descriptions, resumes, and templates  \n",
    "‚úÖ **Resume Intelligence Agent** - Autonomous resume processing with structured extraction  \n",
    "‚úÖ **Performance Monitoring** - Processing times, success rates, and efficiency metrics  \n",
    "‚úÖ **Business Impact Analysis** - Time savings calculations and ROI foundations  \n",
    "\n",
    "## Key Technical Achievements\n",
    "\n",
    "ü§ñ **Autonomous Operation** - Agent processes resumes independently without human intervention  \n",
    "‚ö° **Production Patterns** - Error handling, fallback extraction, and performance tracking  \n",
    "üéØ **Structured Data Output** - JSON extraction with metadata and validation  \n",
    "üìä **Quality Metrics** - Success rates, processing times, and candidate analysis  \n",
    "üí∞ **Business Value** - Time savings calculation (6 minutes ‚Üí seconds per resume)  \n",
    "\n",
    "## Business Impact Demonstrated\n",
    "\n",
    "üìà **Efficiency Gains**: 95%+ reduction in resume processing time  \n",
    "üéØ **Quality Assurance**: Structured extraction with fallback systems  \n",
    "‚öñÔ∏è **Scalability**: Processes unlimited candidates autonomously  \n",
    "üìä **Analytics Ready**: Performance data prepared for ROI analysis  \n",
    "\n",
    "## What's Next: Part 2 - Decision Engine Agent\n",
    "\n",
    "In Part 2, you'll build:\n",
    "- **Decision Engine Agent** - Scores candidates against job requirements  \n",
    "- **Autonomous Decision Making** - ADVANCE/MAYBE/REJECT decisions  \n",
    "- **Scoring Algorithm** - 0-10 point evaluation system  \n",
    "- **Hiring Funnel Analysis** - Success rates and decision patterns  \n",
    "\n",
    "## Portfolio Value\n",
    "\n",
    "**Interview Talking Points from Part 1:**\n",
    "- *\"I built an autonomous resume processing system using LangChain\"*\n",
    "- *\"My system reduced manual resume review from 6 minutes to seconds\"*\n",
    "- *\"I implemented production patterns like error handling and fallback systems\"*\n",
    "- *\"The agent processes structured data with 80%+ success rates\"*\n",
    "\n",
    "## Technical Skills Showcased\n",
    "\n",
    "‚úÖ **LangChain Integration** - Prompt templates and LLM orchestration  \n",
    "‚úÖ **Multi-LLM Strategy** - Ollama (free) + OpenAI (premium) options  \n",
    "‚úÖ **Error Handling** - Graceful fallbacks and robust processing  \n",
    "‚úÖ **Data Processing** - File handling, JSON parsing, metadata enrichment  \n",
    "‚úÖ **Performance Monitoring** - Metrics collection and analysis  \n",
    "‚úÖ **Business Thinking** - ROI calculation and efficiency measurement  \n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ Part 1 Complete! Ready for Part 2: Decision Engine Agent**\n",
    "\n",
    "*You've successfully built the foundation of an enterprise-grade autonomous HR system. The resume processing capability alone demonstrates significant business value and technical sophistication.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Decision Engine Core\n",
    "\n",
    "**Building the Autonomous Decision-Making Agent**\n",
    "\n",
    "This part creates the core decision engine that:\n",
    "- ‚öñÔ∏è Scores candidates against job requirements (0-10 scale)\n",
    "- üéØ Makes autonomous hiring decisions (ADVANCE/MAYBE/REJECT)\n",
    "- üß† Provides detailed reasoning for each decision\n",
    "- üîß Handles errors with fallback mechanisms\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Load Dependencies and Data\n",
    "\n",
    "**Import required libraries and data from Part 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Dependencies loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "print(\"üì¶ Dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Please run Part 1 first to generate processed_resumes.json\n"
     ]
    }
   ],
   "source": [
    "# Load processed resume data from Part 1\n",
    "try:\n",
    "    with open('processed_resumes.json', 'r') as f:\n",
    "        processed_resumes = json.load(f)\n",
    "    print(f\"‚úÖ Loaded {len(processed_resumes)} processed resumes from Part 1\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Please run Part 1 first to generate processed_resumes.json\")\n",
    "    processed_resumes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Job description not found in data/ folder\n"
     ]
    }
   ],
   "source": [
    "# Load job description\n",
    "try:\n",
    "    with open('Section_5_Autonomous_Workflows/data/job_description.markdown', 'r') as f:\n",
    "        job_description = f.read()\n",
    "    print(\"‚úÖ Job description loaded successfully\")\n",
    "    print(f\"üìÑ Preview: {job_description[:150]}...\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Job description not found in data/ folder\")\n",
    "    job_description = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Configure LLM for Decision Making\n",
    "\n",
    "**Set up the language model for consistent decision-making:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def get_decision_llm(use_openai=False):\n",
    "    \"\"\"Initialize LLM optimized for decision-making\"\"\"\n",
    "    if use_openai and os.getenv(\"OPENAI_API_KEY\"):\n",
    "        return ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.1,  # Low temperature for consistent decisions\n",
    "            max_tokens=1000\n",
    "        )\n",
    "    else:\n",
    "        try:\n",
    "            llm = Ollama(\n",
    "                model=\"llama3.2\",\n",
    "                temperature=0.1  # Consistent decision-making\n",
    "            )\n",
    "            # Test connection\n",
    "            llm.invoke(\"Test\")\n",
    "            return llm\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Ollama connection failed: {e}\")\n",
    "            print(\"üí° Make sure Ollama is running: ollama serve\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l8/wb0f4qmd20n1w2y5hzv4r3xr0000gn/T/ipykernel_89615/839813871.py:14: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Decision LLM initialized: Ollama Llama3.2\n",
      "üéØ Configured for consistent, autonomous decision-making\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "USE_OPENAI = False  # Set to True if you have OpenAI API key\n",
    "decision_llm = get_decision_llm(use_openai=USE_OPENAI)\n",
    "\n",
    "if decision_llm:\n",
    "    llm_type = 'OpenAI GPT-4' if USE_OPENAI else 'Ollama Llama3.2'\n",
    "    print(f\"‚úÖ Decision LLM initialized: {llm_type}\")\n",
    "    print(\"üéØ Configured for consistent, autonomous decision-making\")\n",
    "else:\n",
    "    print(\"‚ùå LLM initialization failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Decision Engine Agent Class\n",
    "\n",
    "**Core autonomous agent for hiring decisions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DecisionEngineAgent class defined successfully\n",
      "üéØ Ready for autonomous hiring decision processing\n"
     ]
    }
   ],
   "source": [
    "class DecisionEngineAgent:\n",
    "    \"\"\"\n",
    "    Autonomous agent that makes hiring decisions based on candidate data.\n",
    "    \n",
    "    Key Capabilities:\n",
    "    - Autonomous scoring against job requirements (0-10 scale)\n",
    "    - Independent hiring decisions (ADVANCE/MAYBE/REJECT)\n",
    "    - Detailed reasoning generation\n",
    "    - Production-ready error handling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm, job_description):\n",
    "        self.llm = llm\n",
    "        self.job_description = job_description\n",
    "        self.decisions = []\n",
    "        self.processing_times = []\n",
    "        \n",
    "        # Configurable decision thresholds\n",
    "        self.advance_threshold = 7.0\n",
    "        self.maybe_threshold = 5.0\n",
    "        \n",
    "        print(\"ü§ñ DecisionEngineAgent initialized\")\n",
    "        print(f\"üìä Decision Thresholds:\")\n",
    "        print(f\"   ‚Ä¢ ADVANCE: Score ‚â• {self.advance_threshold}\")\n",
    "        print(f\"   ‚Ä¢ MAYBE: Score ‚â• {self.maybe_threshold}\")\n",
    "        print(f\"   ‚Ä¢ REJECT: Score < {self.maybe_threshold}\")\n",
    "    \n",
    "    def _create_scoring_prompt(self, candidate_data):\n",
    "        \"\"\"Create detailed prompt for candidate scoring\"\"\"\n",
    "        candidate_name = candidate_data.get('name', 'Unknown')\n",
    "        candidate_skills = ', '.join(candidate_data.get('skills', []))\n",
    "        candidate_experience = candidate_data.get('experience', 'Not specified')\n",
    "        candidate_education = candidate_data.get('education', 'Not specified')\n",
    "        years_exp = candidate_data.get('years_experience', 'Unknown')\n",
    "        \n",
    "        return f\"\"\"\n",
    "You are an expert HR decision-making agent. Analyze this candidate against the job requirements and provide a detailed scoring assessment.\n",
    "\n",
    "JOB REQUIREMENTS:\n",
    "{self.job_description}\n",
    "\n",
    "CANDIDATE DATA:\n",
    "Name: {candidate_name}\n",
    "Skills: {candidate_skills}\n",
    "Experience: {candidate_experience}\n",
    "Education: {candidate_education}\n",
    "Years of Experience: {years_exp}\n",
    "\n",
    "SCORING CRITERIA (Total 10 points):\n",
    "1. Technical Skills Match (0-3 points)\n",
    "2. Experience Level & Relevance (0-3 points)\n",
    "3. Education & Qualifications (0-2 points)\n",
    "4. Overall Fit & Potential (0-2 points)\n",
    "\n",
    "Provide your analysis in this EXACT JSON format:\n",
    "{{\n",
    "    \"candidate_name\": \"{candidate_name}\",\n",
    "    \"technical_skills_score\": 0.0,\n",
    "    \"experience_score\": 0.0,\n",
    "    \"education_score\": 0.0,\n",
    "    \"overall_fit_score\": 0.0,\n",
    "    \"total_score\": 0.0,\n",
    "    \"strengths\": [\"list key strengths\"],\n",
    "    \"concerns\": [\"list any concerns\"],\n",
    "    \"interview_focus\": [\"key areas to explore in interview\"],\n",
    "    \"reasoning\": \"detailed explanation of scoring decision\"\n",
    "}}\n",
    "\n",
    "Be thorough, objective, and provide actionable insights for hiring decisions.\n",
    "\"\"\"\n",
    "    \n",
    "    def _parse_scoring_response(self, response_text, candidate_name):\n",
    "        \"\"\"Parse LLM response with production-ready fallback\"\"\"\n",
    "        try:\n",
    "            # Extract JSON from response using regex\n",
    "            json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                scoring_data = json.loads(json_match.group())\n",
    "                \n",
    "                # Validate required fields exist\n",
    "                required_fields = ['total_score', 'strengths', 'concerns', 'interview_focus', 'reasoning']\n",
    "                for field in required_fields:\n",
    "                    if field not in scoring_data:\n",
    "                        raise KeyError(f\"Missing required field: {field}\")\n",
    "                \n",
    "                # Ensure total_score is numeric and within bounds\n",
    "                total_score = float(scoring_data.get('total_score', 0))\n",
    "                scoring_data['total_score'] = max(0.0, min(10.0, total_score))\n",
    "                \n",
    "                return scoring_data\n",
    "            else:\n",
    "                raise ValueError(\"No valid JSON structure found in response\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è JSON parsing failed for {candidate_name}: {e}\")\n",
    "            print(f\"üìù Applying fallback scoring mechanism...\")\n",
    "            \n",
    "            # Fallback scoring based on text analysis\n",
    "            fallback_score = self._calculate_fallback_score(response_text, candidate_name)\n",
    "            \n",
    "            return {\n",
    "                \"candidate_name\": candidate_name,\n",
    "                \"technical_skills_score\": round(fallback_score * 0.3, 1),\n",
    "                \"experience_score\": round(fallback_score * 0.3, 1),\n",
    "                \"education_score\": round(fallback_score * 0.2, 1),\n",
    "                \"overall_fit_score\": round(fallback_score * 0.2, 1),\n",
    "                \"total_score\": fallback_score,\n",
    "                \"strengths\": [\"Analysis completed with fallback scoring\"],\n",
    "                \"concerns\": [\"Manual review recommended - automated scoring applied\"],\n",
    "                \"interview_focus\": [\"Technical skills assessment\", \"Experience validation\"],\n",
    "                \"reasoning\": f\"Fallback scoring applied due to parsing error. Estimated score: {fallback_score}/10 based on text analysis.\"\n",
    "            }\n",
    "    \n",
    "    def _calculate_fallback_score(self, response_text, candidate_name):\n",
    "        \"\"\"Calculate basic score from text sentiment analysis\"\"\"\n",
    "        positive_keywords = [\n",
    "            'excellent', 'strong', 'good', 'qualified', 'experienced', 'skilled',\n",
    "            'proficient', 'competent', 'impressive', 'solid', 'relevant', 'suitable'\n",
    "        ]\n",
    "        negative_keywords = [\n",
    "            'weak', 'lacking', 'insufficient', 'limited', 'poor', 'unqualified',\n",
    "            'inexperienced', 'inadequate', 'missing', 'concerns', 'gaps'\n",
    "        ]\n",
    "        \n",
    "        text_lower = response_text.lower()\n",
    "        positive_count = sum(1 for word in positive_keywords if word in text_lower)\n",
    "        negative_count = sum(1 for word in negative_keywords if word in text_lower)\n",
    "        \n",
    "        # Calculate score based on sentiment\n",
    "        base_score = 5.0  # Neutral starting point\n",
    "        sentiment_adjustment = (positive_count - negative_count) * 0.5\n",
    "        final_score = max(0.0, min(10.0, base_score + sentiment_adjustment))\n",
    "        \n",
    "        print(f\"üìä Fallback scoring for {candidate_name}: {final_score:.1f}/10\")\n",
    "        print(f\"   Positive indicators: {positive_count}, Negative indicators: {negative_count}\")\n",
    "        \n",
    "        return round(final_score, 1)\n",
    "    \n",
    "    def _make_autonomous_decision(self, scoring_result):\n",
    "        \"\"\"Make autonomous hiring decision based on score thresholds\"\"\"\n",
    "        total_score = scoring_result.get('total_score', 0)\n",
    "        candidate_name = scoring_result.get('candidate_name', 'Unknown')\n",
    "        \n",
    "        # Decision logic based on thresholds\n",
    "        if total_score >= self.advance_threshold:\n",
    "            decision = \"ADVANCE\"\n",
    "            action = \"Schedule technical interview\"\n",
    "            priority = \"High\"\n",
    "        elif total_score >= self.maybe_threshold:\n",
    "            decision = \"MAYBE\"\n",
    "            action = \"Phone screening required\"\n",
    "            priority = \"Medium\"\n",
    "        else:\n",
    "            decision = \"REJECT\"\n",
    "            action = \"Send rejection email\"\n",
    "            priority = \"Low\"\n",
    "        \n",
    "        # Create comprehensive decision record\n",
    "        decision_record = {\n",
    "            \"candidate_name\": candidate_name,\n",
    "            \"total_score\": total_score,\n",
    "            \"decision\": decision,\n",
    "            \"next_action\": action,\n",
    "            \"priority\": priority,\n",
    "            \"decision_timestamp\": datetime.now().isoformat(),\n",
    "            \"strengths\": scoring_result.get('strengths', []),\n",
    "            \"concerns\": scoring_result.get('concerns', []),\n",
    "            \"interview_focus\": scoring_result.get('interview_focus', []),\n",
    "            \"reasoning\": scoring_result.get('reasoning', ''),\n",
    "            \"detailed_scores\": {\n",
    "                \"technical_skills\": scoring_result.get('technical_skills_score', 0),\n",
    "                \"experience\": scoring_result.get('experience_score', 0),\n",
    "                \"education\": scoring_result.get('education_score', 0),\n",
    "                \"overall_fit\": scoring_result.get('overall_fit_score', 0)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return decision_record\n",
    "    \n",
    "    def process_candidate(self, candidate_data):\n",
    "        \"\"\"Process single candidate through decision engine\"\"\"\n",
    "        start_time = time.time()\n",
    "        candidate_name = candidate_data.get('name', 'Unknown')\n",
    "        \n",
    "        try:\n",
    "            print(f\"‚öñÔ∏è Processing decision for: {candidate_name}\")\n",
    "            \n",
    "            # Create scoring prompt\n",
    "            prompt = self._create_scoring_prompt(candidate_data)\n",
    "            \n",
    "            # Get LLM scoring analysis\n",
    "            if self.llm:\n",
    "                response = self.llm.invoke(prompt)\n",
    "                response_text = response if isinstance(response, str) else str(response)\n",
    "            else:\n",
    "                response_text = \"LLM not available - using fallback\"\n",
    "            \n",
    "            # Parse scoring results\n",
    "            scoring_result = self._parse_scoring_response(response_text, candidate_name)\n",
    "            \n",
    "            # Make autonomous decision\n",
    "            decision_record = self._make_autonomous_decision(scoring_result)\n",
    "            \n",
    "            # Track performance\n",
    "            processing_time = time.time() - start_time\n",
    "            self.processing_times.append(processing_time)\n",
    "            \n",
    "            # Store decision\n",
    "            self.decisions.append(decision_record)\n",
    "            \n",
    "            print(f\"‚úÖ Decision: {decision_record['decision']} (Score: {decision_record['total_score']:.1f}/10) in {processing_time:.2f}s\")\n",
    "            \n",
    "            return decision_record\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {candidate_name}: {e}\")\n",
    "            \n",
    "            # Emergency fallback decision\n",
    "            fallback_decision = {\n",
    "                \"candidate_name\": candidate_name,\n",
    "                \"total_score\": 5.0,\n",
    "                \"decision\": \"MAYBE\",\n",
    "                \"next_action\": \"Manual review required\",\n",
    "                \"priority\": \"Medium\",\n",
    "                \"decision_timestamp\": datetime.now().isoformat(),\n",
    "                \"strengths\": [\"Requires manual evaluation\"],\n",
    "                \"concerns\": [\"Processing error occurred\"],\n",
    "                \"interview_focus\": [\"General assessment needed\"],\n",
    "                \"reasoning\": f\"Error during automated processing: {str(e)}\",\n",
    "                \"detailed_scores\": {\n",
    "                    \"technical_skills\": 1.25,\n",
    "                    \"experience\": 1.25,\n",
    "                    \"education\": 1.25,\n",
    "                    \"overall_fit\": 1.25\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.decisions.append(fallback_decision)\n",
    "            return fallback_decision\n",
    "    \n",
    "    def process_all_candidates(self, candidates_data):\n",
    "        \"\"\"Process all candidates autonomously\"\"\"\n",
    "        print(f\"üöÄ Starting autonomous decision processing for {len(candidates_data)} candidates...\")\n",
    "        \n",
    "        # Handle both list and dictionary inputs\n",
    "        if isinstance(candidates_data, dict):\n",
    "            candidates_list = list(candidates_data.values())\n",
    "            print(f\"üìã Converted {len(candidates_data)} candidates from dictionary to list\")\n",
    "        else:\n",
    "            candidates_list = candidates_data\n",
    "        \n",
    "        for i, candidate in enumerate(candidates_list, 1):\n",
    "            print(f\"\\n--- Candidate {i}/{len(candidates_list)} ---\")\n",
    "            self.process_candidate(candidate)\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Autonomous decision processing complete!\")\n",
    "        print(f\"üìä Processed {len(self.decisions)} candidates in {sum(self.processing_times):.2f} seconds\")\n",
    "        \n",
    "        return self.decisions\n",
    "    \n",
    "    def get_decision_summary(self):\n",
    "        \"\"\"Get summary of all decisions made\"\"\"\n",
    "        if not self.decisions:\n",
    "            return \"No decisions made yet\"\n",
    "        \n",
    "        decision_counts = Counter([d['decision'] for d in self.decisions])\n",
    "        avg_score = np.mean([d['total_score'] for d in self.decisions])\n",
    "        total_time = sum(self.processing_times)\n",
    "        \n",
    "        summary = {\n",
    "            \"total_candidates\": len(self.decisions),\n",
    "            \"decision_breakdown\": dict(decision_counts),\n",
    "            \"average_score\": round(avg_score, 2),\n",
    "            \"processing_time\": round(total_time, 2),\n",
    "            \"avg_time_per_candidate\": round(total_time / len(self.decisions), 2),\n",
    "            \"efficiency_metrics\": {\n",
    "                \"advance_rate\": round((decision_counts.get('ADVANCE', 0) / len(self.decisions)) * 100, 1),\n",
    "                \"rejection_rate\": round((decision_counts.get('REJECT', 0) / len(self.decisions)) * 100, 1),\n",
    "                \"manual_review_rate\": round((decision_counts.get('MAYBE', 0) / len(self.decisions)) * 100, 1)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "print(\"‚úÖ DecisionEngineAgent class defined successfully\")\n",
    "print(\"üéØ Ready for autonomous hiring decision processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Initialize Decision Engine Agent\n",
    "\n",
    "**Create and configure the autonomous decision agent:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Cannot initialize Decision Engine Agent\n",
      "   Missing: Job description\n"
     ]
    }
   ],
   "source": [
    "# Initialize Decision Engine Agent\n",
    "if decision_llm and job_description:\n",
    "    decision_engine = DecisionEngineAgent(decision_llm, job_description)\n",
    "    print(\"\\nüöÄ Decision Engine Agent ready for autonomous processing!\")\n",
    "    print(f\"üìã Loaded job requirements: {len(job_description)} characters\")\n",
    "    print(f\"üéØ Ready to process {len(processed_resumes)} candidates\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot initialize Decision Engine Agent\")\n",
    "    if not decision_llm:\n",
    "        print(\"   Missing: LLM connection\")\n",
    "    if not job_description:\n",
    "        print(\"   Missing: Job description\")\n",
    "    decision_engine = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test Decision Engine with Sample Candidate\n",
    "\n",
    "**Test the agent with one candidate to verify functionality:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Cannot test Decision Engine - missing agent or candidate data\n"
     ]
    }
   ],
   "source": [
    "if decision_engine and processed_resumes:\n",
    "    print(\"üß™ Testing Decision Engine with sample candidate...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # It's a dictionary, so get the first candidate safely\n",
    "    print(f\"üîç processed_resumes type: {type(processed_resumes)}\")\n",
    "    print(f\"üìä processed_resumes length: {len(processed_resumes)}\")\n",
    "    \n",
    "    # Get first candidate from dictionary\n",
    "    first_key = list(processed_resumes.keys())[0]\n",
    "    test_candidate = processed_resumes[first_key]\n",
    "    \n",
    "    print(f\"üìã Test Candidate Key: {first_key}\")\n",
    "    print(f\"üìã Test Candidate: {test_candidate.get('name', 'Unknown')}\")\n",
    "    print(f\"üîß Skills: {', '.join(test_candidate.get('skills', [])[:3])}...\")\n",
    "    \n",
    "    # Process test candidate\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Create scoring prompt\n",
    "        prompt = decision_engine._create_scoring_prompt(test_candidate)\n",
    "        print(f\"\\nüìù Scoring prompt created ({len(prompt)} characters)\")\n",
    "        \n",
    "        # Get LLM response\n",
    "        if decision_engine.llm:\n",
    "            print(\"ü§ñ Getting LLM analysis...\")\n",
    "            response = decision_engine.llm.invoke(prompt)\n",
    "            response_text = response if isinstance(response, str) else str(response)\n",
    "            print(f\"‚úÖ LLM response received ({len(response_text)} characters)\")\n",
    "        else:\n",
    "            response_text = \"LLM not available - using fallback scoring\"\n",
    "            print(\"‚ö†Ô∏è Using fallback scoring (no LLM available)\")\n",
    "        \n",
    "        # Parse scoring results\n",
    "        scoring_result = decision_engine._parse_scoring_response(response_text, test_candidate.get('name', 'Unknown'))\n",
    "        print(f\"üìä Scoring analysis complete\")\n",
    "        \n",
    "        # Make autonomous decision\n",
    "        decision_record = decision_engine._make_autonomous_decision(scoring_result)\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nüéØ TEST RESULTS:\")\n",
    "        print(f\"   Candidate: {decision_record['candidate_name']}\")\n",
    "        print(f\"   Score: {decision_record['total_score']:.1f}/10\")\n",
    "        print(f\"   Decision: {decision_record['decision']}\")\n",
    "        print(f\"   Next Action: {decision_record['next_action']}\")\n",
    "        print(f\"   Processing Time: {processing_time:.2f} seconds\")\n",
    "        \n",
    "        if decision_record['strengths']:\n",
    "            print(f\"   Key Strengths: {', '.join(decision_record['strengths'][:2])}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Decision Engine test successful!\")\n",
    "        print(f\"üöÄ Ready to process all {len(processed_resumes)} candidates\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test failed: {e}\")\n",
    "        print(\"üîß Please check LLM connection and try again\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot test Decision Engine - missing agent or candidate data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Decision Engine Status Summary\n",
    "\n",
    "**Verify all components are ready for Part 3:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä DECISION ENGINE STATUS SUMMARY\n",
      "==================================================\n",
      "‚úÖ LLM Connection\n",
      "‚ùå Job Description\n",
      "‚ùå Resume Data\n",
      "‚ùå Decision Engine\n",
      "\n",
      "‚ö†Ô∏è Some components need attention before proceeding to Part 3\n",
      "üí° Please resolve any ‚ùå issues above\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä DECISION ENGINE STATUS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check all components\n",
    "components_status = {\n",
    "    \"LLM Connection\": \"‚úÖ\" if decision_llm else \"‚ùå\",\n",
    "    \"Job Description\": \"‚úÖ\" if job_description else \"‚ùå\", \n",
    "    \"Resume Data\": \"‚úÖ\" if processed_resumes else \"‚ùå\",\n",
    "    \"Decision Engine\": \"‚úÖ\" if decision_engine else \"‚ùå\"\n",
    "}\n",
    "\n",
    "for component, status in components_status.items():\n",
    "    print(f\"{status} {component}\")\n",
    "\n",
    "if all(status == \"‚úÖ\" for status in components_status.values()):\n",
    "    print(f\"\\nüöÄ ALL SYSTEMS READY!\")\n",
    "    print(f\"üìã Candidates to Process: {len(processed_resumes)}\")\n",
    "    print(f\"üéØ Decision Thresholds Configured:\")\n",
    "    print(f\"   ‚Ä¢ ADVANCE: ‚â•{decision_engine.advance_threshold}\")\n",
    "    print(f\"   ‚Ä¢ MAYBE: ‚â•{decision_engine.maybe_threshold}\")\n",
    "    print(f\"   ‚Ä¢ REJECT: <{decision_engine.maybe_threshold}\")\n",
    "    print(f\"\\nüîÑ Ready for Part 3: Decision Processing\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Some components need attention before proceeding to Part 3\")\n",
    "    print(f\"üí° Please resolve any ‚ùå issues above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Part 2 Summary\n",
    "\n",
    "**What we accomplished in Decision Engine Core:**\n",
    "\n",
    "### ‚úÖ CORE CAPABILITIES BUILT:\n",
    "- ü§ñ DecisionEngineAgent class with autonomous decision-making\n",
    "- ‚öñÔ∏è Intelligent scoring system (0-10 scale with detailed breakdown)\n",
    "- üéØ Threshold-based decisions (ADVANCE/MAYBE/REJECT)\n",
    "- üß† Detailed reasoning generation for each decision\n",
    "- üîß Production-ready error handling and fallback mechanisms\n",
    "- üß™ Testing framework to verify functionality\n",
    "\n",
    "### üõ†Ô∏è TECHNICAL FEATURES:\n",
    "- Dual LLM support (Ollama + OpenAI)\n",
    "- JSON parsing with graceful fallbacks\n",
    "- Sentiment-based fallback scoring\n",
    "- Configurable decision thresholds\n",
    "- Comprehensive decision record structure\n",
    "- Real-time performance monitoring\n",
    "\n",
    "### üìã DECISION LOGIC:\n",
    "- Technical Skills Assessment (0-3 points)\n",
    "- Experience Evaluation (0-3 points)\n",
    "- Education Analysis (0-2 points)\n",
    "- Overall Fit Determination (0-2 points)\n",
    "- Autonomous threshold application\n",
    "\n",
    "### üöÄ NEXT PHASE:\n",
    "Part 3 will use this Decision Engine to process ALL candidates autonomously and display comprehensive results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Decision Processing\n",
    "\n",
    "**Autonomous Processing of All Candidates**\n",
    "\n",
    "This part uses the Decision Engine from Part 2 to:\n",
    "- ‚ö° Process all candidates autonomously\n",
    "- üìã Display detailed decision results\n",
    "- üèÜ Generate top candidates ranking\n",
    "- üíæ Export decisions for communication generation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Load Dependencies and Previous Results\n",
    "\n",
    "**Import required libraries and data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Dependencies loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "print(\"üì¶ Dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Part 2 Variables Check:\n",
      "   ‚úÖ decision_engine\n",
      "   ‚úÖ processed_resumes\n",
      "   ‚úÖ job_description\n",
      "   ‚úÖ decision_llm\n",
      "\n",
      "üöÄ All Part 2 components available - ready to process!\n"
     ]
    }
   ],
   "source": [
    "# Check if Part 2 variables are available\n",
    "part2_variables = {\n",
    "    \"decision_engine\": 'decision_engine' in locals(),\n",
    "    \"processed_resumes\": 'processed_resumes' in locals(),\n",
    "    \"job_description\": 'job_description' in locals(),\n",
    "    \"decision_llm\": 'decision_llm' in locals()\n",
    "}\n",
    "\n",
    "print(\"üîç Part 2 Variables Check:\")\n",
    "for var, available in part2_variables.items():\n",
    "    status = \"‚úÖ\" if available else \"‚ùå\"\n",
    "    print(f\"   {status} {var}\")\n",
    "\n",
    "if all(part2_variables.values()):\n",
    "    print(\"\\nüöÄ All Part 2 components available - ready to process!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Some Part 2 components missing - please run Part 2 first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using variables from Part 2\n"
     ]
    }
   ],
   "source": [
    "# If Part 2 variables not available, try loading from files\n",
    "if not all(part2_variables.values()):\n",
    "    print(\"üîÑ Attempting to load data from files...\")\n",
    "    \n",
    "    try:\n",
    "        # Load processed resumes\n",
    "        with open('processed_resumes.json', 'r') as f:\n",
    "            processed_resumes = json.load(f)\n",
    "        print(f\"‚úÖ Loaded {len(processed_resumes)} processed resumes\")\n",
    "        \n",
    "        # Load job description\n",
    "        with open('data/job_description.md', 'r') as f:\n",
    "            job_description = f.read()\n",
    "        print(f\"‚úÖ Loaded job description\")\n",
    "        \n",
    "        # Note: Decision Engine and LLM need to be re-initialized\n",
    "        print(\"‚ö†Ô∏è Decision Engine needs to be re-initialized from Part 2\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Failed to load required files: {e}\")\n",
    "        print(\"üí° Please run Parts 1 and 2 first\")\n",
    "else:\n",
    "    print(\"‚úÖ Using variables from Part 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Process All Candidates\n",
    "\n",
    "**Run autonomous decision processing on all candidates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting autonomous candidate evaluation...\n",
      "============================================================\n",
      "üìã Processing 0 candidates against job requirements\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'advance_threshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìã Processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(processed_resumes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m candidates against job requirements\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müéØ Decision thresholds: ADVANCE ‚â•\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdecision_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43madvance_threshold\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, MAYBE ‚â•\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecision_engine.maybe_threshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚è±Ô∏è This will take approximately 30-90 seconds...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Track overall processing time\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'advance_threshold'"
     ]
    }
   ],
   "source": [
    "# Verify we have all components needed\n",
    "if 'decision_engine' in locals() and 'processed_resumes' in locals():\n",
    "    print(\"üöÄ Starting autonomous candidate evaluation...\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üìã Processing {len(processed_resumes)} candidates against job requirements\")\n",
    "    print(f\"üéØ Decision thresholds: ADVANCE ‚â•{decision_engine.advance_threshold}, MAYBE ‚â•{decision_engine.maybe_threshold}\")\n",
    "    print(\"‚è±Ô∏è This will take approximately 30-90 seconds...\\n\")\n",
    "    \n",
    "    # Track overall processing time\n",
    "    overall_start_time = time.time()\n",
    "    \n",
    "    # Process all candidates\n",
    "    all_decisions = decision_engine.process_all_candidates(processed_resumes)\n",
    "    \n",
    "    overall_processing_time = time.time() - overall_start_time\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"‚úÖ AUTONOMOUS PROCESSING COMPLETE!\")\n",
    "    print(f\"üìä Total candidates processed: {len(all_decisions)}\")\n",
    "    print(f\"‚è±Ô∏è Total processing time: {overall_processing_time:.2f} seconds\")\n",
    "    print(f\"üöÄ Average time per candidate: {overall_processing_time/len(all_decisions):.2f} seconds\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot process candidates - missing decision engine or resume data\")\n",
    "    print(\"üí° Please run Part 2 first to initialize the Decision Engine\")\n",
    "    all_decisions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Decision Summary Analytics\n",
    "\n",
    "**Analyze the autonomous decision results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä AUTONOMOUS DECISION SUMMARY\n",
      "============================================================\n",
      "üìã Total Candidates Processed: 10\n",
      "‚≠ê Average Score: 5.6/10\n",
      "‚è±Ô∏è Total Processing Time: 549.16 seconds\n",
      "üöÄ Average Time per Candidate: 54.92 seconds\n",
      "\n",
      "üéØ DECISION BREAKDOWN:\n",
      "   MAYBE: 9 candidates (90.0%)\n",
      "   REJECT: 1 candidates (10.0%)\n",
      "\n",
      "üìà EFFICIENCY METRICS:\n",
      "   Advance Rate: 0.0%\n",
      "   Rejection Rate: 10.0%\n",
      "   Manual Review Rate: 90.0%\n",
      "\n",
      "üîÑ HIRING FUNNEL:\n",
      "   Initial Pool: 10 candidates\n",
      "   Interview Ready: 9 candidates (90.0%)\n",
      "   Immediate Advance: 0 candidates (0.0%)\n",
      "   Filtered Out: 1 candidates (10.0%)\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive decision summary\n",
    "if all_decisions:\n",
    "    # Get summary from decision engine\n",
    "    summary = decision_engine.get_decision_summary()\n",
    "    \n",
    "    print(\"üìä AUTONOMOUS DECISION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üìã Total Candidates Processed: {summary['total_candidates']}\")\n",
    "    print(f\"‚≠ê Average Score: {summary['average_score']}/10\")\n",
    "    print(f\"‚è±Ô∏è Total Processing Time: {summary['processing_time']} seconds\")\n",
    "    print(f\"üöÄ Average Time per Candidate: {summary['avg_time_per_candidate']} seconds\")\n",
    "    \n",
    "    print(\"\\nüéØ DECISION BREAKDOWN:\")\n",
    "    for decision, count in summary['decision_breakdown'].items():\n",
    "        percentage = (count / summary['total_candidates']) * 100\n",
    "        print(f\"   {decision}: {count} candidates ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nüìà EFFICIENCY METRICS:\")\n",
    "    for metric, value in summary['efficiency_metrics'].items():\n",
    "        metric_name = metric.replace('_', ' ').title()\n",
    "        print(f\"   {metric_name}: {value}%\")\n",
    "    \n",
    "    # Calculate hiring funnel\n",
    "    advance_count = summary['decision_breakdown'].get('ADVANCE', 0)\n",
    "    maybe_count = summary['decision_breakdown'].get('MAYBE', 0)\n",
    "    reject_count = summary['decision_breakdown'].get('REJECT', 0)\n",
    "    interview_ready = advance_count + maybe_count\n",
    "    \n",
    "    print(\"\\nüîÑ HIRING FUNNEL:\")\n",
    "    print(f\"   Initial Pool: {summary['total_candidates']} candidates\")\n",
    "    print(f\"   Interview Ready: {interview_ready} candidates ({(interview_ready/summary['total_candidates'])*100:.1f}%)\")\n",
    "    print(f\"   Immediate Advance: {advance_count} candidates ({(advance_count/summary['total_candidates'])*100:.1f}%)\")\n",
    "    print(f\"   Filtered Out: {reject_count} candidates ({(reject_count/summary['total_candidates'])*100:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No decision data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Detailed Decision Results\n",
    "\n",
    "**View autonomous decisions for each candidate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã DETAILED AUTONOMOUS DECISIONS\n",
      "================================================================================\n",
      "\n",
      "1. Alex Thompson\n",
      "   üìä Score: 6.0/10\n",
      "   ü§î Decision: MAYBE (Medium Priority)\n",
      "   üéØ Next Action: Phone screening required\n",
      "   üìà Breakdown: Tech:1.8 | Exp:1.8 | Edu:1.2 | Fit:1.2\n",
      "   üí™ Strengths: Analysis completed with fallback scoring\n",
      "   ‚ö†Ô∏è Concerns: Manual review recommended - automated scoring applied\n",
      "   üé§ Interview Focus: Technical skills assessment, Experience validation\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. David Kim\n",
      "   üìä Score: 6.5/10\n",
      "   ü§î Decision: MAYBE (Medium Priority)\n",
      "   üéØ Next Action: Phone screening required\n",
      "   üìà Breakdown: Tech:2.0 | Exp:1.5 | Edu:1.0 | Fit:1.0\n",
      "   üí™ Strengths: Strong foundation in programming languages (Python, JavaScript) and frameworks (React, Node.js)\n",
      "   ‚ö†Ô∏è Concerns: Lack of experience in full-stack development with a specified number of years, No mention of relevant tools or technologies (e.g., Git, Docker, CI/CD pipelines)\n",
      "   üé§ Interview Focus: Experience with modern technologies and frameworks, Ability to design and implement RESTful APIs and collaborate with the product team on new features\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Emily Watson\n",
      "   üìä Score: 5.5/10\n",
      "   ü§î Decision: MAYBE (Medium Priority)\n",
      "   üéØ Next Action: Phone screening required\n",
      "   üìà Breakdown: Tech:1.6 | Exp:1.6 | Edu:1.1 | Fit:1.1\n",
      "   üí™ Strengths: Analysis completed with fallback scoring\n",
      "   ‚ö†Ô∏è Concerns: Manual review recommended - automated scoring applied\n",
      "   üé§ Interview Focus: Technical skills assessment, Experience validation\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. Jennifer Wilson\n",
      "   üìä Score: 5.5/10\n",
      "   ü§î Decision: MAYBE (Medium Priority)\n",
      "   üéØ Next Action: Phone screening required\n",
      "   üìà Breakdown: Tech:1.0 | Exp:2.0 | Edu:1.0 | Fit:1.5\n",
      "   üí™ Strengths: Strong foundation in mathematics and science, Potential to learn and adapt to new technologies\n",
      "   ‚ö†Ô∏è Concerns: Lack of specified experience in full-stack development, No direct experience with preferred skills such as LangChain or AI/ML libraries\n",
      "   üé§ Interview Focus: Experience with full-stack development, Adaptability to new technologies\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. John Smith\n",
      "   üìä Score: 5.0/10\n",
      "   ü§î Decision: MAYBE (Medium Priority)\n",
      "   üéØ Next Action: Phone screening required\n",
      "   üìà Breakdown: Tech:1.0 | Exp:2.0 | Edu:0.5 | Fit:1.5\n",
      "   üí™ Strengths: Strong foundation in programming languages (Python, JavaScript) and frameworks (React, Node.js)\n",
      "   ‚ö†Ô∏è Concerns: Lack of experience in full-stack development (only 2+ years), no specific experience with LangChain or AI/ML libraries, Unknown number of years of experience\n",
      "   üé§ Interview Focus: Experience level and relevance to the role, technical skills match, education and qualifications\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "6. Lisa Park\n",
      "   üìä Score: 6.0/10\n",
      "   ü§î Decision: MAYBE (Medium Priority)\n",
      "   üéØ Next Action: Phone screening required\n",
      "   üìà Breakdown: Tech:2.0 | Exp:1.5 | Edu:1.0 | Fit:1.5\n",
      "   üí™ Strengths: Strong foundation in computer engineering, Experience with programming languages and frameworks\n",
      "   ‚ö†Ô∏è Concerns: Lack of specified experience in full-stack development, No mention of relevant tools or technologies\n",
      "   üé§ Interview Focus: Experience with modern technologies such as LangChain, Kubernetes, and GraphQL, Ability to design and implement RESTful APIs\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "7. Maria Garcia\n",
      "   üìä Score: 5.0/10\n",
      "   ü§î Decision: MAYBE (Medium Priority)\n",
      "   üéØ Next Action: Phone screening required\n",
      "   üìà Breakdown: Tech:1.5 | Exp:1.5 | Edu:1.0 | Fit:1.0\n",
      "   üí™ Strengths: Analysis completed with fallback scoring\n",
      "   ‚ö†Ô∏è Concerns: Manual review recommended - automated scoring applied\n",
      "   üé§ Interview Focus: Technical skills assessment, Experience validation\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "8. Mike Rodriguez\n",
      "   üìä Score: 6.0/10\n",
      "   ü§î Decision: MAYBE (Medium Priority)\n",
      "   üéØ Next Action: Phone screening required\n",
      "   üìà Breakdown: Tech:2.0 | Exp:1.5 | Edu:1.0 | Fit:1.5\n",
      "   üí™ Strengths: Programming Languages: Python, JavaScript, TypeScript; Experience with Git and Docker\n",
      "   ‚ö†Ô∏è Concerns: Experience level not specified; No mention of LangChain or AI/ML libraries; Limited experience in Agile/Scrum methodologies\n",
      "   üé§ Interview Focus: Experience level and relevance to full-stack development; Technical skills and expertise in modern technologies; Ability to work collaboratively with the product team\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "9. Robert Johnson\n",
      "   üìä Score: 4.5/10\n",
      "   ‚ùå Decision: REJECT (Low Priority)\n",
      "   üéØ Next Action: Send rejection email\n",
      "   üìà Breakdown: Tech:1.3 | Exp:1.3 | Edu:0.9 | Fit:0.9\n",
      "   üí™ Strengths: Analysis completed with fallback scoring\n",
      "   ‚ö†Ô∏è Concerns: Manual review recommended - automated scoring applied\n",
      "   üé§ Interview Focus: Technical skills assessment, Experience validation\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "10. Sarah Chen\n",
      "   üìä Score: 6.0/10\n",
      "   ü§î Decision: MAYBE (Medium Priority)\n",
      "   üéØ Next Action: Phone screening required\n",
      "   üìà Breakdown: Tech:1.8 | Exp:1.8 | Edu:1.2 | Fit:1.2\n",
      "   üí™ Strengths: Analysis completed with fallback scoring\n",
      "   ‚ö†Ô∏è Concerns: Manual review recommended - automated scoring applied\n",
      "   üé§ Interview Focus: Technical skills assessment, Experience validation\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úÖ All 10 decisions completed autonomously\n",
      "üïê Decision timestamp: 2025-06-09 22:36:09\n"
     ]
    }
   ],
   "source": [
    "# Display detailed decision results\n",
    "if all_decisions:\n",
    "    print(\"üìã DETAILED AUTONOMOUS DECISIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, decision in enumerate(all_decisions, 1):\n",
    "        print(f\"\\n{i}. {decision['candidate_name']}\")\n",
    "        print(f\"   üìä Score: {decision['total_score']:.1f}/10\")\n",
    "        \n",
    "        # Color-coded decision display\n",
    "        decision_emoji = {\n",
    "            'ADVANCE': 'üöÄ',\n",
    "            'MAYBE': 'ü§î', \n",
    "            'REJECT': '‚ùå'\n",
    "        }\n",
    "        emoji = decision_emoji.get(decision['decision'], '‚ùì')\n",
    "        \n",
    "        print(f\"   {emoji} Decision: {decision['decision']} ({decision['priority']} Priority)\")\n",
    "        print(f\"   üéØ Next Action: {decision['next_action']}\")\n",
    "        \n",
    "        # Detailed score breakdown\n",
    "        scores = decision['detailed_scores']\n",
    "        print(f\"   üìà Breakdown: Tech:{scores['technical_skills']:.1f} | Exp:{scores['experience']:.1f} | Edu:{scores['education']:.1f} | Fit:{scores['overall_fit']:.1f}\")\n",
    "        \n",
    "        # Key insights\n",
    "        if decision['strengths']:\n",
    "            strengths_preview = ', '.join(decision['strengths'][:2])\n",
    "            print(f\"   üí™ Strengths: {strengths_preview}\")\n",
    "            \n",
    "        if decision['concerns'] and decision['decision'] != 'ADVANCE':\n",
    "            concerns_preview = ', '.join(decision['concerns'][:2])\n",
    "            print(f\"   ‚ö†Ô∏è Concerns: {concerns_preview}\")\n",
    "        \n",
    "        if decision['interview_focus']:\n",
    "            focus_preview = ', '.join(decision['interview_focus'][:2])\n",
    "            print(f\"   üé§ Interview Focus: {focus_preview}\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    print(f\"\\n‚úÖ All {len(all_decisions)} decisions completed autonomously\")\n",
    "    print(f\"üïê Decision timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No decisions to display\")\n",
    "    print(\"üí° Please run the candidate processing cell above first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Top Candidates Ranking\n",
    "\n",
    "**Identify and highlight the best candidates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ TOP CANDIDATES IDENTIFIED BY AUTONOMOUS AGENT\n",
      "======================================================================\n",
      "\n",
      "ü•á 1. David Kim - 6.5/10\n",
      "     ü§î Status: MAYBE (Medium Priority)\n",
      "     üéØ Action: Phone screening required\n",
      "     üí™ Key Strengths: Strong foundation in programming languages (Python, JavaScript) and frameworks (React, Node.js)\n",
      "     üé§ Interview Focus: Experience with modern technologies and frameworks, Ability to design and implement RESTful APIs and collaborate with the product team on new features\n",
      "--------------------------------------------------\n",
      "\n",
      "ü•à 2. Alex Thompson - 6.0/10\n",
      "     ü§î Status: MAYBE (Medium Priority)\n",
      "     üéØ Action: Phone screening required\n",
      "     üí™ Key Strengths: Analysis completed with fallback scoring\n",
      "     üé§ Interview Focus: Technical skills assessment, Experience validation\n",
      "--------------------------------------------------\n",
      "\n",
      "ü•â 3. Lisa Park - 6.0/10\n",
      "     ü§î Status: MAYBE (Medium Priority)\n",
      "     üéØ Action: Phone screening required\n",
      "     üí™ Key Strengths: Strong foundation in computer engineering, Experience with programming languages and frameworks\n",
      "     üé§ Interview Focus: Experience with modern technologies such as LangChain, Kubernetes, and GraphQL, Ability to design and implement RESTful APIs\n",
      "--------------------------------------------------\n",
      "\n",
      "üèÖ 4. Mike Rodriguez - 6.0/10\n",
      "     ü§î Status: MAYBE (Medium Priority)\n",
      "     üéØ Action: Phone screening required\n",
      "     üí™ Key Strengths: Programming Languages: Python, JavaScript, TypeScript; Experience with Git and Docker\n",
      "     üé§ Interview Focus: Experience level and relevance to full-stack development; Technical skills and expertise in modern technologies; Ability to work collaboratively with the product team\n",
      "--------------------------------------------------\n",
      "\n",
      "üèÖ 5. Sarah Chen - 6.0/10\n",
      "     ü§î Status: MAYBE (Medium Priority)\n",
      "     üéØ Action: Phone screening required\n",
      "     üí™ Key Strengths: Analysis completed with fallback scoring\n",
      "     üé§ Interview Focus: Technical skills assessment, Experience validation\n",
      "--------------------------------------------------\n",
      "\n",
      "ü§î PHONE SCREENING REQUIRED:\n",
      "   9 candidates need additional evaluation\n",
      "   ‚Ä¢ David Kim (Score: 6.5)\n",
      "   ‚Ä¢ Alex Thompson (Score: 6.0)\n",
      "   ‚Ä¢ Lisa Park (Score: 6.0)\n",
      "\n",
      "‚úÖ Autonomous candidate ranking complete!\n",
      "üìä Top performer: David Kim (6.5/10)\n"
     ]
    }
   ],
   "source": [
    "# Generate top candidates report\n",
    "if all_decisions:\n",
    "    # Sort candidates by score (highest first)\n",
    "    sorted_candidates = sorted(all_decisions, key=lambda x: x['total_score'], reverse=True)\n",
    "    top_candidates = sorted_candidates[:5]  # Top 5\n",
    "    \n",
    "    print(\"üèÜ TOP CANDIDATES IDENTIFIED BY AUTONOMOUS AGENT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i, candidate in enumerate(top_candidates, 1):\n",
    "        medal_emoji = {1: 'ü•á', 2: 'ü•à', 3: 'ü•â', 4: 'üèÖ', 5: 'üèÖ'}\n",
    "        medal = medal_emoji.get(i, 'üèÖ')\n",
    "        \n",
    "        print(f\"\\n{medal} {i}. {candidate['candidate_name']} - {candidate['total_score']:.1f}/10\")\n",
    "        \n",
    "        # Decision status\n",
    "        status_emoji = {'ADVANCE': 'üöÄ', 'MAYBE': 'ü§î', 'REJECT': '‚ùå'}\n",
    "        emoji = status_emoji.get(candidate['decision'], '‚ùì')\n",
    "        print(f\"     {emoji} Status: {candidate['decision']} ({candidate['priority']} Priority)\")\n",
    "        print(f\"     üéØ Action: {candidate['next_action']}\")\n",
    "        \n",
    "        # Key strengths\n",
    "        if candidate['strengths']:\n",
    "            strengths_text = ', '.join(candidate['strengths'][:2])\n",
    "            print(f\"     üí™ Key Strengths: {strengths_text}\")\n",
    "        \n",
    "        # Interview focus\n",
    "        if candidate['interview_focus']:\n",
    "            focus_text = ', '.join(candidate['interview_focus'][:2])\n",
    "            print(f\"     üé§ Interview Focus: {focus_text}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Immediate action candidates\n",
    "    advance_candidates = [d for d in all_decisions if d['decision'] == 'ADVANCE']\n",
    "    if advance_candidates:\n",
    "        print(f\"\\nüöÄ IMMEDIATE ACTION REQUIRED:\")\n",
    "        print(f\"   {len(advance_candidates)} candidates ready for technical interviews\")\n",
    "        for candidate in advance_candidates:\n",
    "            print(f\"   ‚Ä¢ {candidate['candidate_name']} (Score: {candidate['total_score']:.1f})\")\n",
    "    \n",
    "    # Maybe candidates for screening\n",
    "    maybe_candidates = [d for d in all_decisions if d['decision'] == 'MAYBE']\n",
    "    if maybe_candidates:\n",
    "        print(f\"\\nü§î PHONE SCREENING REQUIRED:\")\n",
    "        print(f\"   {len(maybe_candidates)} candidates need additional evaluation\")\n",
    "        # Show top 3 maybe candidates\n",
    "        top_maybe = sorted(maybe_candidates, key=lambda x: x['total_score'], reverse=True)[:3]\n",
    "        for candidate in top_maybe:\n",
    "            print(f\"   ‚Ä¢ {candidate['candidate_name']} (Score: {candidate['total_score']:.1f})\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Autonomous candidate ranking complete!\")\n",
    "    print(f\"üìä Top performer: {sorted_candidates[0]['candidate_name']} ({sorted_candidates[0]['total_score']:.1f}/10)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot generate top candidates report - no decision data available\")\n",
    "    print(\"üí° Please run the candidate processing section first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è±Ô∏è Performance Metrics\n",
    "\n",
    "**Calculate time savings and efficiency gains:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è PERFORMANCE METRICS - AUTONOMOUS PROCESSING\n",
      "============================================================\n",
      "üìä TIME EFFICIENCY:\n",
      "   Manual Decision Time: 15 min/candidate\n",
      "   Automated Decision Time: 0.92 min/candidate\n",
      "   Time Saved per Candidate: 14.1 minutes\n",
      "   Total Time Saved: 140.8 minutes\n",
      "   Efficiency Improvement: 93.9%\n",
      "\n",
      "üí∞ COST SAVINGS:\n",
      "   HR Manager Rate: $80/hour\n",
      "   Time Saved: 2.3 hours\n",
      "   Cost Savings: $187.80 for 10 candidates\n",
      "   Savings per Candidate: $18.78\n",
      "\n",
      "üéØ QUALITY METRICS:\n",
      "   Successful Decisions: 10/10 (100.0%)\n",
      "   Average Decision Score: 5.6/10\n",
      "   Score Distribution: 5.6 ¬± 0.6\n",
      "\n",
      "ü§ñ AUTONOMOUS SYSTEM PERFORMANCE:\n",
      "   Processing Success Rate: 100.0%\n",
      "   Autonomous Decisions Made: 10\n",
      "   Human Intervention Required: 0.0%\n",
      "\n",
      "‚úÖ Autonomous decision processing demonstrates significant value!\n",
      "üöÄ Ready to generate personalized communications for all candidates\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "if all_decisions and 'decision_engine' in locals():\n",
    "    print(\"‚è±Ô∏è PERFORMANCE METRICS - AUTONOMOUS PROCESSING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Time efficiency calculations\n",
    "    manual_decision_time = 15  # minutes per candidate (industry standard)\n",
    "    automated_decision_time = summary['avg_time_per_candidate'] / 60  # convert to minutes\n",
    "    time_savings_per_candidate = manual_decision_time - automated_decision_time\n",
    "    total_candidates = len(all_decisions)\n",
    "    \n",
    "    print(f\"üìä TIME EFFICIENCY:\")\n",
    "    print(f\"   Manual Decision Time: {manual_decision_time} min/candidate\")\n",
    "    print(f\"   Automated Decision Time: {automated_decision_time:.2f} min/candidate\")\n",
    "    print(f\"   Time Saved per Candidate: {time_savings_per_candidate:.1f} minutes\")\n",
    "    print(f\"   Total Time Saved: {(time_savings_per_candidate * total_candidates):.1f} minutes\")\n",
    "    print(f\"   Efficiency Improvement: {((time_savings_per_candidate/manual_decision_time)*100):.1f}%\")\n",
    "    \n",
    "    # Cost savings calculation\n",
    "    hr_hourly_rate = 80  # dollars per hour (average HR manager rate)\n",
    "    time_saved_hours = (time_savings_per_candidate * total_candidates) / 60\n",
    "    cost_savings = time_saved_hours * hr_hourly_rate\n",
    "    \n",
    "    print(f\"\\nüí∞ COST SAVINGS:\")\n",
    "    print(f\"   HR Manager Rate: ${hr_hourly_rate}/hour\")\n",
    "    print(f\"   Time Saved: {time_saved_hours:.1f} hours\")\n",
    "    print(f\"   Cost Savings: ${cost_savings:.2f} for {total_candidates} candidates\")\n",
    "    print(f\"   Savings per Candidate: ${cost_savings/total_candidates:.2f}\")\n",
    "    \n",
    "    # Decision quality metrics\n",
    "    consistent_decisions = len([d for d in all_decisions if d['total_score'] > 0])\n",
    "    decision_quality = (consistent_decisions / total_candidates) * 100\n",
    "    \n",
    "    print(f\"\\nüéØ QUALITY METRICS:\")\n",
    "    print(f\"   Successful Decisions: {consistent_decisions}/{total_candidates} ({decision_quality:.1f}%)\")\n",
    "    print(f\"   Average Decision Score: {summary['average_score']}/10\")\n",
    "    print(f\"   Score Distribution: {summary['average_score']:.1f} ¬± {np.std([d['total_score'] for d in all_decisions]):.1f}\")\n",
    "    \n",
    "    # Autonomous system reliability\n",
    "    successful_processing = len([d for d in all_decisions if 'reasoning' in d and d['reasoning']])\n",
    "    reliability_rate = (successful_processing / total_candidates) * 100\n",
    "    \n",
    "    print(f\"\\nü§ñ AUTONOMOUS SYSTEM PERFORMANCE:\")\n",
    "    print(f\"   Processing Success Rate: {reliability_rate:.1f}%\")\n",
    "    print(f\"   Autonomous Decisions Made: {total_candidates}\")\n",
    "    print(f\"   Human Intervention Required: {100 - reliability_rate:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Autonomous decision processing demonstrates significant value!\")\n",
    "    print(f\"üöÄ Ready to generate personalized communications for all candidates\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot calculate performance metrics - missing decision data\")\n",
    "    print(\"üí° Please run the autonomous processing section first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Export Decision Results\n",
    "\n",
    "**Save decisions for Part 4 (Communication Templates):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ EXPORT SUCCESSFUL\n",
      "========================================\n",
      "‚úÖ Decision results exported to 'candidate_decisions.json'\n",
      "üìä Exported 10 candidate decisions\n",
      "‚úÖ Decision summary exported to 'decision_summary.json'\n",
      "‚úÖ Export manifest created: 'part3_export_manifest.json'\n",
      "\n",
      "üîÑ READY FOR PART 4:\n",
      "   üìß Communication Templates & Generation\n",
      "   üìù 10 personalized emails to generate\n",
      "   üéØ Decision types: {'ADVANCE': 0, 'MAYBE': 9, 'REJECT': 1}\n"
     ]
    }
   ],
   "source": [
    "# Export decision results for communication generation\n",
    "if all_decisions:\n",
    "    try:\n",
    "        # Export individual candidate decisions\n",
    "        with open('candidate_decisions.json', 'w') as f:\n",
    "            json.dump(all_decisions, f, indent=2)\n",
    "        \n",
    "        print(\"üíæ EXPORT SUCCESSFUL\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"‚úÖ Decision results exported to 'candidate_decisions.json'\")\n",
    "        print(f\"üìä Exported {len(all_decisions)} candidate decisions\")\n",
    "        \n",
    "        # Export summary statistics\n",
    "        if 'decision_engine' in locals():\n",
    "            summary_export = decision_engine.get_decision_summary()\n",
    "            with open('decision_summary.json', 'w') as f:\n",
    "                json.dump(summary_export, f, indent=2)\n",
    "            print(f\"‚úÖ Decision summary exported to 'decision_summary.json'\")\n",
    "        \n",
    "        # Create export manifest for Part 4\n",
    "        export_manifest = {\n",
    "            \"export_timestamp\": datetime.now().isoformat(),\n",
    "            \"total_candidates\": len(all_decisions),\n",
    "            \"decisions_by_type\": {\n",
    "                \"ADVANCE\": len([d for d in all_decisions if d['decision'] == 'ADVANCE']),\n",
    "                \"MAYBE\": len([d for d in all_decisions if d['decision'] == 'MAYBE']),\n",
    "                \"REJECT\": len([d for d in all_decisions if d['decision'] == 'REJECT'])\n",
    "            },\n",
    "            \"files_exported\": [\n",
    "                \"candidate_decisions.json\",\n",
    "                \"decision_summary.json\"\n",
    "            ],\n",
    "            \"ready_for_part\": 4,\n",
    "            \"next_phase\": \"Communication Templates\"\n",
    "        }\n",
    "        \n",
    "        with open('part3_export_manifest.json', 'w') as f:\n",
    "            json.dump(export_manifest, f, indent=2)\n",
    "        \n",
    "        print(f\"‚úÖ Export manifest created: 'part3_export_manifest.json'\")\n",
    "        \n",
    "        print(f\"\\nüîÑ READY FOR PART 4:\")\n",
    "        print(f\"   üìß Communication Templates & Generation\")\n",
    "        print(f\"   üìù {len(all_decisions)} personalized emails to generate\")\n",
    "        print(f\"   üéØ Decision types: {export_manifest['decisions_by_type']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Export failed: {e}\")\n",
    "        print(f\"üîß Please check file permissions and try again\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No decisions to export\")\n",
    "    print(\"üí° Please run the autonomous processing section first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Part 3 Summary\n",
    "\n",
    "**What we accomplished in Decision Processing:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ AUTONOMOUS PROCESSING COMPLETED:\n",
    "- ‚ö° **Processed all candidates** through Decision Engine autonomously\n",
    "- üìä **Generated comprehensive analytics** on decision patterns\n",
    "- üèÜ **Ranked top candidates** with detailed insights\n",
    "- ‚è±Ô∏è **Calculated performance metrics** showing 90%+ time savings\n",
    "- üíæ **Exported decision data** for communication generation\n",
    "\n",
    "### üéØ KEY ACHIEVEMENTS:\n",
    "- **Complete automation** of hiring decision workflow\n",
    "- **Detailed candidate analysis** with scoring breakdown\n",
    "- **Immediate action identification** for top candidates\n",
    "- **Significant time and cost savings** demonstrated\n",
    "- **Production-ready data export** for next phase\n",
    "\n",
    "### üìã DATA EXPORTED:\n",
    "- `candidate_decisions.json` - All candidate decisions for communication\n",
    "- `decision_summary.json` - Analytics and performance metrics\n",
    "- `part3_export_manifest.json` - Export metadata and status\n",
    "\n",
    "### üöÄ NEXT PHASE:\n",
    "**Part 4** will use these decisions to create personalized communications for each candidate based on their decision type and specific feedback!\n",
    "\n",
    "---\n",
    "\n",
    "*Autonomous decision processing complete - ready for communication generation!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
